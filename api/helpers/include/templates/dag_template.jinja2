import requests
import time
from airflow import DAG
from airflow.operators.http_operator import SimpleHttpOperator
from airflow.operators.python_operator import PythonOperator  # Import PythonOperator
from airflow.sensors.time_delta import TimeDeltaSensor
from airflow.utils.dates import days_ago
from datetime import timedelta
from airflow.providers.slack.notifications.slack import send_slack_notification
from airflow.utils.task_group import TaskGroup

import json

def check_api_response():
    while True:
        try:
            response = requests.get('https://httpbin.org/get')
            if response.status_code == 200:
                response_json = response.json()
                if response_json['url'] == 'https://httpbin.org/get':
                    response_status = True
                    print('API response is true')
                    break
                else:
                    print('API response is not true, retrying in 60 seconds...')
                    time.sleep(60)
            else:
                print('API request failed with status code', response.status_code)
                time.sleep(60)
        except Exception as err:
            time.sleep(60)
            print(err)

default_args = {
    'owner': 'me',
    'start_date': days_ago(1),
    'retries': -1,  # Set to None for unlimited retries
    'retry_delay': timedelta(seconds=30),
}

{% for dag_ in dag %}
dag = DAG(
    "{{ dag_.dag_id }}",
    default_args=default_args,
    schedule_interval=timedelta(hours=1),
    catchup={{ dag_.catchup or False }}
)
{% endfor %}

def task_success_callback(**context):
    """
    Callback function to check the task's state and decide whether to retry or not.
    """
    task_instance = context['task_instance']
    task_state = task_instance.current_state()
    if task_state == "success":
        return True
    else:
        return False

check_api = PythonOperator(
    task_id='check_api',
    python_callable=check_api_response,
    dag=dag
    # retries=0,  # Set to 0, as we are handling retries manually
    # retry_delay=timedelta(seconds=30),  # Delay between retries
    # Callback function to decide whether to retry or not
)


{% set delay_durations = data_seconds %}
duration_data = {{ data_seconds }}

{% set http_tasks = [] %}
http_tasks = []
{% set prev_response = None %}

# Define the first HTTP operator separately
http_task_1 = SimpleHttpOperator(
    task_id="{{ operators[0].task_id }}",
    http_conn_id="{{ operators[0].http_conn_id }}",
    endpoint="{{ operators[0].endpoint }}",
    method="{{ operators[0].method }}",
    headers={{ operators[0].headers | tojson }},  # Assuming headers is a dictionary, convert it to JSON
    data=json.dumps({{ operators[0].data}}),
    log_response={{ operators[0].log_response }},
    dag=dag,
    do_xcom_push=True,
    on_failure_callback=[
        send_slack_notification(
            text="The task {{ operators[0].task_id }} failed",
            channel="#airflow-error",
            username="airflow",
        )
    ],
)
http_tasks.append(http_task_1)

# Set up task dependencies with dynamic delay durations
{% if operators|length > 1 %}
{% for i in range(1, operators|length) %}

# Downstream task to retrieve XCom value
{% if i >= 1 %}
# Define the HTTP operator
http_task_{{ i + 1 }} = SimpleHttpOperator(
    task_id="{{ operators[i].task_id }}",
    http_conn_id="{{ operators[i].http_conn_id }}",
    endpoint="{{ operators[i].endpoint }}",
    method="{{ operators[i].method }}",
    headers={{ operators[i].headers | tojson }},  # Assuming headers is a dictionary, convert it to JSON
    data=json.dumps({{ operators[i].data }}),
    log_response={{ operators[i].log_response }},
    do_xcom_push=True,  # Enable pushing response to XCom
    dag=dag,
    on_failure_callback=[
        send_slack_notification(
            text="The task {{ operators[i].task_id }} failed",
            channel="#airflow-error",
            username="airflow",
        )
    ],
)
http_tasks.append(http_task_{{ i + 1 }})
{% if operators[i].urls is not none %}

def process_json_response_{{i}}(**context):
    ti = context['task_instance']
    prev_json_data = ti.xcom_pull(task_ids='{{ operators[i-1].task_id }}', key='return_value')
    chunk_size = 1
    if prev_json_data:
        response = None
        print(prev_json_data)
        if "data" in prev_json_data:
            print(json.loads(prev_json_data).get("data", []))
            data_list = json.loads(prev_json_data).get("data", [])  # Get the list of dictionaries under "data" key
            if data_list:
                for i in range(0, len(data_list), chunk_size):
                    for url_ in [json.loads(url_data) for url_data in {{operators[i].urls}}]:
                        chunk = data_list[i:i + chunk_size]
                        print(chunk)
                        # Send the chunk of requests
                        response = requests.post(url=url_['url'], json=chunk)
                    
                        # Check the response status code
                        if response.status_code == 200:
                            print(response.json())
                            json_data = response.json()
                            # context['task_instance'].xcom_push(key='json_response', value=json_data)
                        else:
                            print(f'Request failed with status code {response.status_code}')
                    
                        # Wait for 20 seconds before sending the next chunk
                        time.sleep(int(url_['delay']))
            else:
                raise Exception("the dataset is empty")
                
            
        
            
        

process_response_{{i}}_task = PythonOperator(
    task_id='process_response_{{ operators[i].task_id }}',
    python_callable=process_json_response_{{i}},
    provide_context=True,
    retries=1,  # Override the retries for this task
    retry_delay=timedelta(minutes=1), 
    dag=dag
)

    
{% endif %}


{% endif %}

# Set up task dependencies with dynamic delay durations
{% if loop.index|string in delay_durations and loop.index > 1 and operators[loop.index].data is not none%}
# Add delay sensor between tasks
delay_task_{{ loop.index }} = TimeDeltaSensor(
    task_id='delay_task_{{ loop.index }}',
    delta=timedelta(seconds=duration_data[str({{ loop.index }})]),  # Use dynamic delay durations from the dictionary
    mode='reschedule',
    dag=dag,
)
check_api >> http_task_{{ loop.index - 1 }} >> delay_task_{{ loop.index }} >> http_task_{{ loop.index }}
{% elif loop.index > 1 and operators[loop.index].data is not none %}
http_task_{{ loop.index - 1 }} >> http_task_{{ loop.index }}
{% elif loop.index|string not in delay_durations and loop.index > 1 and operators[loop.index].data is none %}
http_task_{{ loop.index }} >> process_response_{{loop.index}}_task 
{% endif %}

{% endfor %}
{% endif %}
